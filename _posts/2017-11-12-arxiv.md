---
title: 'arXiv Person Re-identification'
date: 2017-11-12
permalink: /posts/2017/11/arxiv/
tags:
  - arXiv
  - Person Re-identification
  - Computer Vision
---

arXiv与Person Re-identification相关。

<span id="back"></span>
# List

1. [(1703)In Defense of the Triplet Loss for Person Re-Identification](#jump1) [[pdf](https://arxiv.org/pdf/1703.07737)] [[github](https://github.com/VisualComputingInstitute/triplet-reid)]
2. (1703)SVDNet for Pedestrian Retrieval [[pdf](https://arxiv.org/pdf/1703.05693)] [[github](https://github.com/syfafterzy/SVDNet-for-Pedestrian-Retrieval)]
3. [(1711)AlignedReID: Surpassing Human-Level Performance in Person Re-Identification](#jump3) [[pdf](https://arxiv.org/pdf/1711.08184.pdf)]

# Notes

<span id="jump1"></span>
## 1. In Defense of the Triplet Loss for Person Re-Identification [Back](#back)

又一篇基于 Triplet 的力作。在 re-id 社区认为一个 classification loss 联合一个 verification loss 对这个问题更有效时，再一次用一种改进的 Triplet loss 实现了端到端的特征提取加度量学习的深度学习方法，超过了目前 state-of-the-art 的方法一个较大的边界。文章中作者首先指出了 Classification 和 Verification 两种 loss 方法的明显缺点：

- Classification：随着行人 id 的增长，网络中需要学习的参数也将迅速增长，然而这些增长在训练结束后并没有多大的意义。
- Verification：这种 loss 需用于图片之间，如比较两张图片的相似度，当面临行人检索等问题时，需要一对一对的进行比较，这将大大增加测试时所投入的代价。

而使用 Triplet loss 能够明显避免以上缺点，进行 End-to-end 的特征提取与度量学习的训练，并最终通过简单的距离（如欧式距离）计算，在特征空间中对行人间的距离进行比较。

然而 Triplet 使用时的难点在于：

- 如果使用朴素的 Triplet，并不能得到很好地结果。Triplet 中一个很重要部分是如何挖掘 Hard Triplets 进行有效的特征学习，否则训练将会很快停滞不前。
- 如果一味追求 Hard Triplets，将会非常耗时，且无法明确定义什么是一个“好”的 Hard Triplets。此外，选用过多的 Hard Triplets 还可能会使训练变得十分不稳定而无法收敛。

总的来说本文有两点贡献：
- 首先，本文提出了一种含有一定 Hard Triplets 挖掘能力的经典 Triplet loss 的变体，并系统地评测了各种 Triplet loss 变体的性能。
- 与以往的认识不同，本文还展示了仅仅使用 Triplet loss 而无需添加特殊的网络层级结构等其它方法，在预训练好的 CNN 和从头开始训练的网络模型上，都能取得 state-of-the-art 的结果。

## Triplet Loss & Importance of Mining


**FaceNet Triplet loss**

FaceNet针对LMNN loss提取了其改进版本，命名为Triplet loss：

<div align="center" >
<img src="/images/arxiv2017/dentri-1.PNG" width="70%" align="center" />
</div>

如果在整个数据集上经过足够长时间的训练，Triplet最终能将所有的正样本pull到一起。然而当数据集变得越来越大时，triplets的数量将呈现三次指数增长，使得进行充分训练变得不切实际。此外，通过triplet loss学习到的映射将很快就能正确判断大部分普通的triplets，导致大量triplets在训练时将毫无作用。因此，进行Hard Triplets的挖掘变得十分重要。Hard Triplets包含hard negatives（相似外观的不同行人）和hard positives（外观姿态变化较大的同一行人）。

**Batch All Triplet Loss**

与FaceNet数据的组织方式不同，本文用了一个改进的方式组织一个batch：每个batch随机采样P个class，每个class随机采样K个imgs，这样每个batch有PK个imgs。对于这种batch组织方式，共有PK(PK-1)(K-1)中triplets的组合，简单地，如果选择所有triplets用于计算loss，可以得到一下的loss形式，称为Batch All Triplet Loss：

<div align="center" >
<img src="/images/arxiv2017/dentri-2.PNG" width="70%" align="center" />
</div>

**Batch Hard Triplet Loss**

Batch All Triplet Loss一次将要处理大量的triplets，这在数据集非常大时会非常耗时，并且在训练进入中后期时，大量的三元组因为很容易被区分导致对最后的loss并没有任何贡献而变成“无用的”三元组。

这时可以考虑进行Hard Mining，然后过多的Hard Mining会导致训练非常不稳定，于是作者提出了一种折中的办法，进行Moderate Hard Mining，并由此定义了Moderate Triplets，由于这只是在一个batch中最难的数据，因此总得来说，这只是较难的，也最适合用于triplet训练，称之为Batch Hard Triplet Loss：

<div align="center" >
<img src="/images/arxiv2017/dentri-3.PNG" width="70%" align="center" />
</div>

其中<img src="http://chart.googleapis.com/chart?cht=tx&chl=$x_j^i|$" style="border:none;">表示第i个人的第j张图片。

**Distance Measure**

在很多工作中，人们都使用了平方的欧氏距离
<img src="http://chart.googleapis.com/chart?cht=tx&chl=$D(a,b)=||a-b||^2_2$" style="border:none;">
作为度量函数，本文中虽然没有系统性地对其它度量函数进行对比，但是在实验中发现真实的欧氏距离
<img src="http://chart.googleapis.com/chart?cht=tx&chl=$ D(a,b)=||a-b||_2_ $" style="border:none;">
表现得更加稳定。同时，使用非平方的真实的欧氏距离也使得margin这个参数更具有可解释性。

**Soft-margin**

之前的triplet loss都采用了hinge形式的函数对loss进行截断处理，即如果triplet关系正确则loss为0。这里作者发现，对于Re-ID任务，持续不断地将同类目标在特征空间中的位置pull在一起是非常有益的。出于此种目的，作者对于原始的hinge函数用softplus函数进行了更平滑的近似：

<div align="center" >
<img src="/images/arxiv2017/dentri-4.PNG" width="70%" align="center" />
</div>

## 实验

实验使用的数据集为Market-1501和MARS，优化时选择了Adam而非SGD，训练时进行了学习率退火。在网络结构的选取上，分两种进行实验：
- Pretrained-TriNet：使用预训练好的Resnet-50，去掉其最后一层后添加两个全连接层，第一层有1024维，后跟上batch norm和ReLU，第二层为128维，亦是最终特征的维度，使用BH Triplet loss进行训练。
- Trained from Scratch-LuNet：沿用Resnet-v2，但使用了leaky ReLU激活函数，使用3x3的max-pool，其步长为2.这个网络比TriNet轻量很多，

作者首先对各种Triplet loss训练的效果进行了对比：

<div align="center" >
<img src="/images/arxiv2017/dentri-5.PNG" align="center" />
</div>

- 没有Hard Mining的结果往往不好，如果加上简单的offline hard-mining（OHM）效果会很不稳定。
- BH形式的loss整体上表现好于BA。作者认为，由于训练后期大量triplets的loss都是0，人后平均处理会把仅有的有效信息给稀释掉。于是作者又做了补充实验，在计算平均的时候只考虑loss不为0的triplet，发现对BA形式loss的效果确实有所提高。
- 在所有的形式中，Batch Hard+Soft-margin的效果最好，但这并不代表在其它任务中这种组合依然是最好的，需要更多的实验验证。

<span id="jump2"></span>
## 3. AlignedReID: Surpassing Human-Level Performance in Person Re-Identification [Back](#back)

**Outline**

- 动态对准(Dynamic Alignment)：端到端让网络自动学习人体对齐，计算最短路径作为loss，与Moderate Triplet loss一起训练
- 协同学习(Mutual Learning)：同时训练两个网络，互相学习
- 重排序(Re-Ranking)：使用了k-reciprocal encoding做重排序

**Motivation**

在考虑人体结构对齐时，既不是简单地分成几截，也不需要像其它一些精细的方法引入额外标注进行骨架估计等方法来对齐，而是用一种端到端的方法让网络自动学习人体对齐。

在AlignedReID中，与其它方法类似，会同时提取global特征和local特征。网络结构如下：

<div align="center" >
<img src="/images/arxiv2017/aligned-3.PNG" width="100%" align="center" />
</div>

之后对于两张图片中任意一对局部信息，计算距离并最终构成一个距离矩阵。之后动态地计算从矩阵左上角到右下角的最短路径，这条路径的一条鞭就对应了一对局部特征的匹配。这种人体对齐的方式，保证了身体各个部分的相对顺序，并且对齐方式的总距离总是最短的。在训练的时候，最短路径的长度被加入到损失函数中，辅助学习行人的整体特征。

<div align="center" >
<img src="/images/arxiv2017/aligned-1.PNG" width="60%" align="center" />
</div>

此外，在训练时还是用了协同学习策略，即同时训练两个网络并使它们互相学习，这种方法常用于分类问题中，此处做了一定修改使之适用于此处的度量学习。

在协同学习时，同时训练的两个网络每一个都包含两个分支，一个分支做分类，一个分支做度量学习。做分类的分支通过KL Divergence互相学习；做度量学习的分支通过metric mutual loss互相学习。其中做度量学习的分支又包含两个子分支：全局特征的分支和局部特征的分支。训练完成后，分类分支和局部特征的分支都将被丢弃，只保留全局特征的分支做ReID，即行人分类和通过人体对齐学习局部特征，都只是为了辅助得到更好的全局特征。

<div align="center" >
<img src="/images/arxiv2017/aligned-2.PNG" width="100%" align="center" />
</div>

最后作者还使用了k-reciprocal encoding做重排序进一步提升结果。本文方法在CUHK03、Market1501、CUHK-SYSU上都取得了最好的结果。同时，也在视频数据集MARS上做了实验，用此方法仅仅通过简单的对一个tracklet上所有图片特征的简单平均，就能得到比现有视频中最好的方法还要好很多的结果。

**Results**

|metric|Market-1501(SQ)|CUHK03|MARS|CUHK-SYSU|
|:-----:|:-----:|:-----:|:-----:|:-----:|
|**CMC top-1**|**94.00**|**96.1**|**87.5**|**95.3**|
|**mAP**|**91.2**|-|85.6|93.7|



[Back](#back)
